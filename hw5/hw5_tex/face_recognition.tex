\qns{PCA and face recognition}
\newline
One observation from the face dataset analysis exercise in HW3 (feel free to look over HW3 solutions) is that we may be able to take advantage of our analysis for developing a simple face recognition algorithm.  Recall from HW3, that  we 
let $x_i \in \mathbf{R}^m, i = 1, \hdots, n$, be the given data points (images represented as vectors) to analyze, and denoted $\hat{x} =  \frac{1}{n}\sum_{i =1}^{n} x_i $, the mean of the data points with $ \tilde{x_i} = x_i - \hat{x}$, the centered datapoint. In addition, 
\begin{equation*}
\Tilde{X} = 
\begin{bmatrix}
    \leftarrow \tilde{x}_1^T \rightarrow \\
    \leftarrow \tilde{x}_2^T \rightarrow \\
    \vdots       \\
    \leftarrow \tilde{x}_n^T \rightarrow
\end{bmatrix}
\in \mathbf{R}^{n \times m}
\end{equation*}
is the matrix such that the $i$-th row is $\Tilde{x}_i^T$.
\\

We also observed that the direction of the $i$-th greatest variation corresponded to the 
right singular vector corresponding the $i$-th singular value (arranged in descending order) of $\Tilde{X}$. 

The idea for face recognition is this, we can approximately describe any face image from our dataset by subtracting the mean and projecting it onto the directions of maximal variation. 
Now, given a mean subtracted (centered) data point $\tilde{x}$ and the unit norm direction of $i$-th maximal variation $v_i$, this projection is the quantity:
\begin{equation*}
   \tilde{\alpha}_i(\tilde{x})v_i \coloneqq (\tilde{x}^Tv_i)v_i 
\end{equation*}
It is known as the $i$-th principal component of the data point $\tilde{x}$. 
\\
Given a datapoint $\tilde{x}$ and $k$ directions of maximal variation $v_i, \hspace{5pt} i=1, \hdots, k$ we may project this datapoint onto all the $k$ directions.
\\
Let 
\begin{equation*}
    \tilde{\mathbf{\alpha}}(\tilde{x}) \coloneqq 
    \begin{bmatrix}
        \tilde{\alpha}_1(\tilde{x}) \\
        \tilde{\alpha}_2(\tilde{x}) \\
        \vdots\\
        \tilde{\alpha}_k(\tilde{x}) \\
    \end{bmatrix}
    \in \mathbf{R}^{k}
\end{equation*}
be a vector containing all these projections for a given $\tilde{x}$.
\begin{enumerate}
     \item
    Given the mean of the datapoints $\hat{x}$, the $k$ directions of maximal variation $\{v_i, \hspace{5pt} i=1,\hdots, k\}$ and a data point $x$ drawn from the same distribution as the dataset, derive a matrix vector equation for $\tilde{\mathbf{\alpha}}(x)$. (\emph{Hint}: You should first write an equation for $\tilde{\alpha}(\tilde{x})$ and then write $\tilde{x}$ as a function of $x$.)
    \newline
    
    \sol{\input{face_recognition_solution/1.1.tex}}
    
    \item
    Implement this function in the Ipython notebook for this section. 
    \newline
    
    \sol{\input{face_recognition_solution/1.2.tex}}
    
    \item
    For any data point $x$, we may think of $\tilde{\mathbf{\alpha}}(x)$ as a description of that data point. Consequently, to compare two data points, $x_a, x_b$, we can compare $\tilde{\mathbf{\alpha}}(x_a)$ and $\tilde{\mathbf{\alpha}}(x_b)$.
    Why is this more efficient than comparing just $x_a, x_b$? (Hint, typically $k \ll m$).
    \newline
    
    \sol{\input{face_recognition_solution/1.3.tex}}
    
    \item
    For face recognition, the equality of two image matrices is sufficient but not necessary to imply that both images are of the same face. For example, if you take a picture frowning and another smiling, it is still your face even though the image matrices may not be the same. By projecting the data on only the top k components, we hope to be able to discard unimportant information about a face and thus obtain a more robust way of comparing faces. In the Ipython notebook, run the first two examples (you should uncomment the lines to update the filenames, one at a time) to find the most similar face in the dataset to the query images. Note: The query images were not present in the dataset. 
    \newline
    
    \sol{\input{face_recognition_solution/1.4.tex}}
    
    \item
    Run it again for the next two images. In which cases does this face recognition algorithm work? Why would it not work sometimes? Note: There are more advance techniques for better face detection using deep learning that go beyond the limitations of our simple algorithm.
    
    \sol{\input{face_recognition_solution/1.5.tex}}
\end{enumerate}